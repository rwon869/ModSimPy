{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# China's One Child Policy\n",
    "\n",
    "At what point are there too many men?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from modsim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>10.51040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>10.66790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>10.84035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>11.01630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>11.18650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>11.35185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>11.50780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>11.64970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>11.78440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>11.91835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>12.04855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>12.17550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>12.30075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>12.41935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>12.52735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>12.62645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>12.71850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>12.80400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>12.88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>12.96075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>13.03720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>13.11020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>13.17885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>13.24655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>13.31260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>13.37705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>13.44130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>13.50695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>13.57380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>13.64270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>13.71220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>13.78665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>13.83981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>13.88738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>13.92929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>13.96550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Population\n",
       "Year            \n",
       "1985    10.51040\n",
       "1986    10.66790\n",
       "1987    10.84035\n",
       "1988    11.01630\n",
       "1989    11.18650\n",
       "1990    11.35185\n",
       "1991    11.50780\n",
       "1992    11.64970\n",
       "1993    11.78440\n",
       "1994    11.91835\n",
       "1995    12.04855\n",
       "1996    12.17550\n",
       "1997    12.30075\n",
       "1998    12.41935\n",
       "1999    12.52735\n",
       "2000    12.62645\n",
       "2001    12.71850\n",
       "2002    12.80400\n",
       "2003    12.88400\n",
       "2004    12.96075\n",
       "2005    13.03720\n",
       "2006    13.11020\n",
       "2007    13.17885\n",
       "2008    13.24655\n",
       "2009    13.31260\n",
       "2010    13.37705\n",
       "2011    13.44130\n",
       "2012    13.50695\n",
       "2013    13.57380\n",
       "2014    13.64270\n",
       "2015    13.71220\n",
       "2016    13.78665\n",
       "2017    13.83981\n",
       "2018    13.88738\n",
       "2019    13.92929\n",
       "2020    13.96550"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/rwon/Documents/ModSim/Date_Range.csv\",  index_col='Year', low_memory=False) / 1e8\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>death_rate</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probOfBeingBoy</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old_pop0</th>\n",
       "      <td>4.906175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young_pop0</th>\n",
       "      <td>4.906175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ageWhenMature</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngMale0</th>\n",
       "      <td>2.453088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngFemale0</th>\n",
       "      <td>2.453088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldMale0</th>\n",
       "      <td>2.453088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldFemale0</th>\n",
       "      <td>2.453088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fertilityRate</th>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "death_rate         0.600000\n",
       "probOfBeingBoy     0.100000\n",
       "old_pop0           4.906175\n",
       "young_pop0         4.906175\n",
       "ageWhenMature     18.000000\n",
       "youngMale0         2.453088\n",
       "youngFemale0       2.453088\n",
       "oldMale0           2.453088\n",
       "oldFemale0         2.453088\n",
       "fertilityRate      1.600000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = System(death_rate = 0.6,\n",
    "                probOfBeingBoy = 0.1,\n",
    "                old_pop0 = 4.906175,\n",
    "                young_pop0 = 4.906175,\n",
    "                ageWhenMature = 18,\n",
    "                youngMale0 = 2.4530875,\n",
    "                youngFemale0 = 2.4530875,\n",
    "                oldMale0 = 2.4530875,\n",
    "                oldFemale0 = 2.4530875,\n",
    "                fertilityRate = 1.6) #age at which young -> old and has a baby\n",
    "\n",
    "systemSingle = System(t0 = 1985, \n",
    "                      t_end = 2010)\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t0</th>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_end</th>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "t0       1985\n",
       "t_end    2010\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systemSingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-22-c1f82778562e>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-c1f82778562e>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    oldTotal\"\"\"\"\u001b[0m\n\u001b[1;37m                \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"people = [[],[],[],[],[],[],[]] #creating a list series\n",
    "youngMale = people[0]\n",
    "youngFemale = people[1]\n",
    "youngTotal = people[2]\n",
    "oldMale = people[3]\n",
    "oldFemale = people[4]\n",
    "oldTotal = people[5]\n",
    "population = people[6]\n",
    "\n",
    "youngMale = [None]*max(systemSingle.t_end)\n",
    "youngFemale = [None]*max(systemSingle.t_end)\n",
    "youngTotal = [None]*max(systemSingle.t_end)\n",
    "oldMale = [None]*max(systemSingle.t_end)\n",
    "oldFemale = [None]*max(systemSingle.t_end)\n",
    "oldTotal = [None]*max(systemSingle.t_end)\n",
    "population = [None]*max(systemSingle.t_end)\n",
    "\n",
    "oldTotal\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.5455,\n",
       " 7.7451,\n",
       " 7.96025,\n",
       " 8.18315,\n",
       " 8.41105,\n",
       " 8.6203,\n",
       " 8.8194,\n",
       " 9.0035,\n",
       " 9.16395,\n",
       " 9.30685,\n",
       " 9.43455,\n",
       " 9.56165,\n",
       " 9.69005,\n",
       " 9.81235,\n",
       " 9.93885,\n",
       " 10.0863,\n",
       " 10.2331,\n",
       " 10.36825]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforePolicy=[7.54550, 7.74510,7.96025,8.18315,8.41105,8.62030,8.81940,9.00350,9.16395,9.30685,9.43455,9.56165,9.69005,9.81235,9.93885,10.08630,10.23310,10.36825]\n",
    "beforePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulation(system):\n",
    " #   people = [[],[],[],[],[],[]] #creating a list series\n",
    "    youngMale = TimeSeries()\n",
    "    youngFemale = TimeSeries()\n",
    "    youngTotal = TimeSeries()\n",
    "    oldMale = TimeSeries()\n",
    "    oldFemale = TimeSeries()\n",
    "    oldTotal = TimeSeries()\n",
    "   # population = people[6]\n",
    "    population = TimeSeries()\n",
    "\n",
    "   # youngMale = [None]*max(systemSingle.t_end+2)\n",
    "   # youngFemale = [None]*max(systemSingle.t_end+2)\n",
    "   # youngTotal = [None]*max(systemSingle.t_end+2)\n",
    "   # oldMale = [None]*max(systemSingle.t_end+2)\n",
    "   # oldFemale = [None]*max(systemSingle.t_end+2)\n",
    "   # oldTotal = [None]*max(systemSingle.t_end+2)\n",
    "   #population = [None]*max(system.t_end+2)\n",
    "\n",
    "    oldTotal[systemSingle.t0] = system.old_pop0\n",
    "    youngTotal[systemSingle.t0] = system.young_pop0\n",
    "    youngMale[systemSingle.t0] = system.youngMale0\n",
    "    youngFemale[systemSingle.t0] = system.youngFemale0\n",
    "    oldMale[systemSingle.t0] = system.oldMale0\n",
    "    oldFemale[systemSingle.t0] = system.oldFemale0\n",
    "    population[systemSingle.t0] = system.old_pop0 + system.young_pop0\n",
    "    \n",
    "    \n",
    "    for t in range(systemSingle.t0, systemSingle.t_end):\n",
    "        i = 0\n",
    "        \n",
    "        if t < (systemSingle.t0 + system.ageWhenMature):\n",
    "            maturationsGirls = beforePolicy[i]/2\n",
    "            maturationsBoys = beforePolicy[i]/2\n",
    "            \n",
    "            babiesNextYear = maturationsGirls\n",
    "            \n",
    "            youngMale[t+1] = babiesNextYear*system.probOfBeingBoy + youngMale[t]\n",
    "            youngFemale[t+1] = babiesNextYear - youngMale[t+1] + youngFemale[t]\n",
    "            youngTotal[t+1] = youngMale[t+1] + youngFemale[t+1] + youngTotal[t]\n",
    "            \n",
    "            deaths = system.death_rate * oldTotal[t]\n",
    "            \n",
    "            oldFemale[t+1] = maturationsGirls + oldFemale[t] - deaths/2\n",
    "            oldMale[t+1] = maturationsBoys + oldMale[t] - deaths/2\n",
    "            oldTotal[t+1] = oldFemale[t+1] + oldMale[t+1]\n",
    "            population[t+1] = youngTotal[t+1] + oldTotal[t+1]\n",
    "            \n",
    "            i+=1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            maturationsGirls = youngFemale[int(t - system.ageWhenMature)]\n",
    "            maturationsBoys = youngMale[int(t - system.ageWhenMature)]\n",
    "            \n",
    "            babiesNextYear = maturationsGirls\n",
    "            \n",
    "            youngMale[t+1] = babiesNextYear*system.probOfBeingBoy + youngMale[t] - maturationsBoys\n",
    "            youngFemale[t+1] = babiesNextYear - youngMale[t+1] + youngFemale[t] - maturationsGirls\n",
    "            youngTotal[t+1] = youngMale[t+1] + youngFemale[t+1] + youngTotal[t]\n",
    "            \n",
    "            deaths = system.death_rate * oldTotal[t]\n",
    "            \n",
    "            oldFemale[t+1] = maturationsGirls + oldFemale[t] - deaths/2\n",
    "            oldMale[t+1] = maturationsBoys + oldMale[t] - deaths/2\n",
    "            oldTotal[t+1] = oldFemale[t+1] + oldMale[t+1]\n",
    "            \n",
    "            population[t+1] = youngTotal[t+1] + oldTotal[t+1]\n",
    "           \n",
    "    system.population = population\n",
    "    system.youngMale = youngMale\n",
    "    system.youngFemale = youngFemale\n",
    "    system.youngTotal = youngTotal\n",
    "    system.oldMale = oldMale\n",
    "    system.oldFemale = oldFemale\n",
    "    system.oldTotal = oldTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your changes in `run_simulation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>2.453088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>3.395475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>3.960587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>4.148425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>3.958987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>3.392275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2.448287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1.127025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-0.571513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-2.647325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-5.100413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-7.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-11.138413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-14.723325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-18.685513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>-23.024975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>-27.741712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-32.835725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-38.307012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-45.343271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>-49.888715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>-51.622580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-50.186375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-45.183881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-36.181152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-22.706515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1985     2.453088\n",
       "1986     3.395475\n",
       "1987     3.960587\n",
       "1988     4.148425\n",
       "1989     3.958987\n",
       "1990     3.392275\n",
       "1991     2.448287\n",
       "1992     1.127025\n",
       "1993    -0.571513\n",
       "1994    -2.647325\n",
       "1995    -5.100413\n",
       "1996    -7.930775\n",
       "1997   -11.138413\n",
       "1998   -14.723325\n",
       "1999   -18.685513\n",
       "2000   -23.024975\n",
       "2001   -27.741712\n",
       "2002   -32.835725\n",
       "2003   -38.307012\n",
       "2004   -45.343271\n",
       "2005   -49.888715\n",
       "2006   -51.622580\n",
       "2007   -50.186375\n",
       "2008   -45.183881\n",
       "2009   -36.181152\n",
       "2010   -22.706515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simulation(system)\n",
    "system.youngFemale\n",
    "#system.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(system, title=None):\n",
    "    \"\"\"Plot the estimates and the model.\n",
    "    \n",
    "    system: System object with `results`\n",
    "    \"\"\"\n",
    "    newfig()\n",
    "    plot(data, '--', color='green', label='China Population')\n",
    "    plot(system.population, 'bo-', label='population')\n",
    "    decorate(xlabel='Time (years)', \n",
    "             ylabel='Population of China (in millions)',\n",
    "             title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEjCAYAAACfJW4sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncs4bI+eccznnjZFzzrmc+38TZ6dnc+ROkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f8b899a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(system, title='One Child Policy Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function plot in module modsim:\n",
      "\n",
      "plot(*args, **kwargs)\n",
      "    Makes line plots.\n",
      "    \n",
      "    args can be:\n",
      "      plot(y)\n",
      "      plot(y, style_string)\n",
      "      plot(x, y)\n",
      "      plot(x, y, style_string)\n",
      "    \n",
      "    kwargs are the same as for pyplot.plot\n",
      "    \n",
      "    If x or y have attributes label and/or units,\n",
      "    label the axes accordingly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TimeSeries in module modsim:\n",
      "\n",
      "class TimeSeries(MySeries)\n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, dict, or scalar value\n",
      " |      Contains data stored in Series\n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex(len(data)) if not provided. If both a dict and index\n",
      " |      sequence are used, the index will override the keys found in the\n",
      " |      dict.\n",
      " |  dtype : numpy.dtype or None\n",
      " |      If None, dtype will be inferred\n",
      " |  copy : boolean, default False\n",
      " |      Copy input data\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TimeSeries\n",
      " |      MySeries\n",
      " |      pandas.core.series.Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.strings.StringAccessorMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from MySeries:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize a Series.\n",
      " |      \n",
      " |      Note: this cleans up a weird Series behavior, which is\n",
      " |      that Series() and Series([]) yield different results.\n",
      " |      See: https://github.com/pandas-dev/pandas/issues/16737\n",
      " |  \n",
      " |  set(self, **kwargs)\n",
      " |      Uses keyword arguments to update the Series in place.\n",
      " |      \n",
      " |      Example: series.update(a=1, b=2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right, name='__add__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321158>)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321840>)\n",
      " |  \n",
      " |  __divmod__ = wrapper(left, right, name='__divmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F8835CA60>)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right, name='__floordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F883219D8>)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      provide iteration over the values of the Series\n",
      " |      box values if necessary\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right, name='__mod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321B70>)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right, name='__mul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F883216A8>)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right, name='__pow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321D08>)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right, name='__radd__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321378>)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88359378>)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right, name='__rfloordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88359598>)\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right, name='__rmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F883599D8>)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right, name='__rmul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321EA0>)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right, name='__rpow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F883597B8>)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right, name='__rsub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88359158>)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88359378>)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right, name='__sub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321510>)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000023F88321840>)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using callable, string, dict, or list of string/callables\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      " |      default behavior is applying the function along axis=0\n",
      " |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      " |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      " |      \n",
      " |      agg is an alias for aggregate. Use it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using callable, string, dict, or list of string/callables\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      " |      default behavior is applying the function along axis=0\n",
      " |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      " |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      " |      \n",
      " |      agg is an alias for aggregate. Use it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two object on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0, 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0, 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |  \n",
      " |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      \n",
      " |          .. versionadded: 0.19.0\n",
      " |      \n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      Series.agg: only perform aggregating type operations\n",
      " |      Series.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      >>> series\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...         return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of maximum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmax\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of minimum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmin\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right. NA values\n",
      " |      will be treated as False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary\n",
      " |      right : scalar\n",
      " |          Right boundary\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_between : Series\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, *args, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative max over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : boolean, default False\n",
      " |      If True, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return Series without null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      valid : Series\n",
      " |      inplace : boolean, default False\n",
      " |          Do operation in place.\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Return boolean Series denoting duplicate values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      freq : None or string alias / date offset object, default=None (DEPRECATED)\n",
      " |          Frequency to conform to before computing statistic\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |  \n",
      " |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      freq : string or DateOffset object, optional (default None) (DEPRECATED)\n",
      " |          Frequency to conform the data to before computing the statistic.\n",
      " |          Specified as a frequency string or DateOffset object.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0, 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return label for first non-NA/null value\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : label\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See matplotlib documentation online for more on this\n",
      " |  \n",
      " |  idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of maximum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmax\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of minimum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmin\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return a boolean :class:`~pandas.Series` showing whether each element\n",
      " |      in the :class:`~pandas.Series` is exactly contained in the passed\n",
      " |      sequence of ``values``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          ``list`` of one element.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |          Support for values as a set\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If ``values`` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(list('abc'))\n",
      " |      >>> s.isin(['a', 'c', 'e'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('a')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['a'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return label for last non-NA/null value\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (which can be\n",
      " |      a dict, Series, or function)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          same index as caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Map inputs to outputs (both of type `Series`)\n",
      " |      \n",
      " |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      " |      >>> x\n",
      " |      one      1\n",
      " |      two      2\n",
      " |      three    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      " |      >>> y\n",
      " |      1    foo\n",
      " |      2    bar\n",
      " |      3    baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      If `arg` is a dictionary, return a new Series with values converted\n",
      " |      according to the dictionary's mapping:\n",
      " |      \n",
      " |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      " |      \n",
      " |      >>> x.map(z)\n",
      " |      one   A\n",
      " |      two   B\n",
      " |      three C\n",
      " |      \n",
      " |      Use na_action to control whether NA values are affected by the mapping\n",
      " |      function.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      " |      \n",
      " |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3    this is a string nan\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3                     NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply: For applying more complex functions on a Series\n",
      " |      DataFrame.apply: Apply a function row-/column-wise\n",
      " |      DataFrame.applymap: Apply a function elementwise on a whole DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When `arg` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``:\n",
      " |      \n",
      " |      >>> from collections import Counter\n",
      " |      >>> counter = Counter()\n",
      " |      >>> counter['bar'] += 1\n",
      " |      >>> y.map(counter)\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Memory usage of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool\n",
      " |          Specifies whether to include memory usage of Series index\n",
      " |      deep : bool\n",
      " |          Introspect the data deeply, interrogate\n",
      " |          `object` dtypes for system-level memory consumption\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar bytes of memory consumed\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array if deep=False\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatability with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Returns the difference between the maximum value and the\n",
      " |                  minimum value in the object. This is the equivalent of the\n",
      " |                  ``numpy.ndarray`` method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      Applies the `put` method to its `values` attribute\n",
      " |      if it has one.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : array-like, optional (can be specified in order, or as\n",
      " |          keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only  applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      for compatibility with higher dims\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter axes input function or functions. Function / dict values must be\n",
      " |      unique (1-to-1). Labels not contained in a dict / Series will be left\n",
      " |      as-is. Extra labels listed don't throw an error. Alternatively, change\n",
      " |      ``Series.name`` with a scalar value (Series only).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, list-like, dict-like or function, optional\n",
      " |          Scalar or list-like will alter the ``Series.name`` attribute,\n",
      " |          and raise on DataFrame or Panel.\n",
      " |          dict-like or functions are transformations to apply to\n",
      " |          that axis' values\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.NDFrame.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(2)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      TypeError: 'int' object is not callable\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      " |         a  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis : where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, *args, **kwargs)\n",
      " |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `repeats` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Analogous to the :meth:`pandas.DataFrame.reset_index` function, see\n",
      " |      docstring there.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns\n",
      " |      name : object, default None\n",
      " |          The name of the column corresponding to the Series values\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the Series in place (do not create a new object)\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      resetted : DataFrame, or Series if drop == True\n",
      " |  \n",
      " |  reshape(self, *args, **kwargs)\n",
      " |      DEPRECATED: calling this method will raise an error in a\n",
      " |      future release. Please call ``.values.reshape(...)`` instead.\n",
      " |      \n",
      " |      return an ndarray with the values shape\n",
      " |      if the specified shape matches exactly the current shape, then\n",
      " |      return self (for compat)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.reshape\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculcations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      freq : string or DateOffset object, optional (default None) (DEPRECATED)\n",
      " |          Frequency to conform the data to before computing the statistic.\n",
      " |          Specified as a frequency string or DateOffset object.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. See the notes below.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicity set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int\n",
      " |          Number of decimal places to round to (default: 0).\n",
      " |          If decimals is negative, it specifies the number of\n",
      " |          positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      DataFrame.round\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'])\n",
      " |      array([1])\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread', 'eggs'])\n",
      " |      array([1, 4])\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      " |      array([3, 4])    # eggs before milk\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained, a\n",
      " |      new object is created with the label placed at the end of the result\n",
      " |      index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0, 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      " |      Sort object by labels (along an axis)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : index to direct sorting\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          if not None, sort on values in specified index level(s)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending vs. descending\n",
      " |      inplace : bool, default False\n",
      " |          if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      " |           Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          if true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values along either axis\n",
      " |      \n",
      " |      .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 'index'}, default 0\n",
      " |          Axis to direct sorting\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      DEPRECATED: use :meth:`Series.sort_index`\n",
      " |      \n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=True, is_copy=False, **kwargs)\n",
      " |      return Series corresponding to requested indices\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      convert : translate negative to positive indices (default)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.take\n",
      " |  \n",
      " |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |      Convert Series to {label -> value} dict\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : dict\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      " |      Write Series to an excel sheet\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Convert Series to a nested list\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values`\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values in the object. Uniques are returned in order\n",
      " |      of appearance, this does NOT sort. Hash table-based unique.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : 1d array-like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unique values.\n",
      " |        - If the input is an Index, the return is an Index\n",
      " |        - If the input is a Categorical dtype, the return is a Categorical\n",
      " |        - If the input is a Series/ndarray, the return will be an ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique\n",
      " |      Index.unique\n",
      " |      Series.unique\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded: 0.18.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |  \n",
      " |  valid lambda self, inplace=False, **kwargs\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      " |  \n",
      " |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file (DISCOURAGED, please use :func:`pandas.read_csv`\n",
      " |      instead).\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  asobject\n",
      " |      return object Series which contains boxed values\n",
      " |      \n",
      " |      *this is an internal non-public method*\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  cat = <class 'pandas.core.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |      Accessor object for datetimelike properties of the Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.dt.hour\n",
      " |      >>> s.dt.second\n",
      " |      >>> s.dt.quarter\n",
      " |      \n",
      " |      Returns a Series indexed like the original Series.\n",
      " |      Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort by values\n",
      " |      na_sentinel: int, default -1\n",
      " |          Value to mark \"not found\"\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : the indexer to the original array\n",
      " |      uniques : the unique Index\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_unique : boolean\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return an object with absolute value taken--only applicable to objects\n",
      " |      that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs: type of caller\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Concatenate prefix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_prefix : type of caller\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Concatenate suffix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_suffix : type of caller\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |             .. versionadded: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast object to input numpy.dtype\n",
      " |      Return a copy when copy = True (be really careful with this!)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : DEPRECATED use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |      upper : float or array_like, default None\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |                0         1\n",
      " |      0  0.335232 -1.256177\n",
      " |      1 -1.367855  0.746646\n",
      " |      2  0.027753 -1.176076\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  1.261967  0.570967\n",
      " |      \n",
      " |      >>> df.clip(-1.0, 0.5)\n",
      " |                0         1\n",
      " |      0  0.335232 -1.000000\n",
      " |      1 -1.000000  0.500000\n",
      " |      2  0.027753 -1.000000\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  0.500000  0.500000\n",
      " |      \n",
      " |      >>> t\n",
      " |      0   -0.3\n",
      " |      1   -0.2\n",
      " |      2   -0.1\n",
      " |      3    0.0\n",
      " |      4    0.1\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 1, axis=0)\n",
      " |                0         1\n",
      " |      0  0.335232 -0.300000\n",
      " |      1 -0.200000  0.746646\n",
      " |      2  0.027753 -0.100000\n",
      " |      3  0.230930  0.000000\n",
      " |      4  1.100000  0.570967\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None)\n",
      " |      Return copy of the input with values below given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      DEPRECATED: consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Deprecated.\n",
      " |      \n",
      " |      Attempt to infer better dtype for object columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this objects data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean or string, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices or the data are copied.\n",
      " |      \n",
      " |          Note that when ``deep=True`` data is copied, actual python objects\n",
      " |          will not be copied recursively, only the reference to the object.\n",
      " |          This is in contrast to ``copy.deepcopy`` in the Standard Library,\n",
      " |          which recursively copies object data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : type of caller\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to categorical\n",
      " |            objects submit the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To select numeric types submit\n",
      " |            ``numpy.number``. To select categorical objects submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If ``include='all'``\n",
      " |      is provided as an option, the result will include a union of\n",
      " |      attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 'a'], [2, 'b'], [3, 'c']],\n",
      " |      ...                   columns=['numeric', 'object'])\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              numeric object\n",
      " |      count       3.0      3\n",
      " |      unique      NaN      3\n",
      " |      top         NaN      b\n",
      " |      freq        NaN      1\n",
      " |      mean        2.0    NaN\n",
      " |      std         1.0    NaN\n",
      " |      min         1.0    NaN\n",
      " |      25%         1.5    NaN\n",
      " |      50%         2.0    NaN\n",
      " |      75%         2.5    NaN\n",
      " |      max         3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         b\n",
      " |      freq        1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         b\n",
      " |      freq        1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  drop(self, labels, axis=0, level=None, inplace=False, errors='raise')\n",
      " |      Return new object with labels in requested axis removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |      axis : int or axis name\n",
      " |      level : int or level name, default None\n",
      " |          For MultiIndex\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and existing labels are dropped.\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : type of caller\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.select\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.first('10D') -> First 10 days\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return the counts of dtypes in this object.\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return the counts of ftypes in this object.\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, str, or iterable\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A str or list of strs\n",
      " |          may be passed to group by the columns in ``self``\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are null.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      notnull : boolean inverse of isnull\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('5M') -> Last 5 months\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is False and otherwise are from\n",
      " |      other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          If cond is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are\n",
      " |      not null.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      isnull : boolean inverse of notnull\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      .. versionadded:: 0.16.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : positional arguments passed into ``func``.\n",
      " |      kwargs : a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      on Series or DataFrames. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter index and / or columns using input function or functions.\n",
      " |      A scalar or list-like for ``mapper`` will alter the ``Index.name``\n",
      " |      or ``MultiIndex.names`` attribute.\n",
      " |      A function or dict for ``mapper`` will alter the labels.\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, dict-like or function, optional\n",
      " |      axis : int or string, default 0\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.NDFrame.rename\n",
      " |      pandas.Index.rename\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")  # scalar, alters df.index.name\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      >>> df.rename_axis(lambda x: 2 * x)  # function: alters labels\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |      >>> df.rename_axis({\"A\": \"ehh\", \"C\": \"see\"}, axis=\"columns\")  # mapping\n",
      " |         ehh  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      " |      Replace values given in 'to_replace' with 'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      " |      \n",
      " |          * str or regex:\n",
      " |      \n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str and regex rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      " |                follows: look in column 'a' for the value 'b' and replace it\n",
      " |                with nan. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |              - Keys map to column names and values map to substitution\n",
      " |                values. You can treat this as a special case of passing two\n",
      " |                lists except that you are specifying the column to search in.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the ``regex`` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or Series\n",
      " |                of such elements. If `value` is also ``None`` then this\n",
      " |                **must** be a nested dictionary or ``Series``.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      " |          specifying which value to use for each column (columns not in the\n",
      " |          dict will not be filled). Regular expressions, strings and lists or\n",
      " |          dicts of such objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column form a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      " |          parameter will be interpreted as a regular expression or a list,\n",
      " |          dict, or array of regular expressions.\n",
      " |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when ``to_replace`` is a\n",
      " |          ``list``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NDFrame.reindex\n",
      " |      NDFrame.asfreq\n",
      " |      NDFrame.fillna\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : NDFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      " |            regular expression or is a list, dict, ndarray, or Series.\n",
      " |      ValueError\n",
      " |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      " |            they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point numbers\n",
      " |        *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Returns a random sample of items from an axis of object.\n",
      " |      \n",
      " |      .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, axis, labels)\n",
      " |      public verson of axis assignment\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows\n",
      " |  \n",
      " |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      " |      Attempt to write text representation of object to the system clipboard\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : boolean, defaults to True\n",
      " |              if True, use the provided separator, writing in a csv\n",
      " |              format for allowing easy pasting into excel.\n",
      " |              if False, write a string representation of the object\n",
      " |              to the clipboard\n",
      " |      sep : optional, defaults to tab\n",
      " |      other keywords are passed to to_csv\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform\n",
      " |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      " |        - Windows: none\n",
      " |        - OS X: none\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path (string) or HDFStore object\n",
      " |      key : string\n",
      " |          identifier for the group in the store\n",
      " |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      " |      \n",
      " |        ``'w'``\n",
      " |            Write; a new file is created (an existing file with the same\n",
      " |            name would be deleted).\n",
      " |        ``'a'``\n",
      " |            Append; an existing file is opened for reading and writing,\n",
      " |            and if the file does not exist it is created.\n",
      " |        ``'r+'``\n",
      " |            It is similar to ``'a'``, but the file must already exist.\n",
      " |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      " |          fixed(f) : Fixed format\n",
      " |                     Fast writing/reading. Not-appendable, nor searchable\n",
      " |          table(t) : Table format\n",
      " |                     Write as a PyTables Table structure which may perform\n",
      " |                     worse but allow more flexible operations like searching\n",
      " |                     / selecting subsets of the data\n",
      " |      append : boolean, default False\n",
      " |          For Table formats, append the input data to the existing\n",
      " |      data_columns :  list of columns, or True, default None\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See `here\n",
      " |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      " |      \n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : int, 0-9, default 0\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc', None}, default None\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |           'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum\n",
      " |      dropna : boolean, default False.\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path or buffer to write the result string\n",
      " |          if this is None, return a StringIO of the converted string\n",
      " |      orient : string\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - split : dict like\n",
      " |              {index -> [index], columns -> [columns], data -> [values]}\n",
      " |            - records : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - index : dict like {index -> {column -> value}}\n",
      " |            - columns : dict like {column -> {index -> value}}\n",
      " |            - values : just the values array\n",
      " |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      " |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      " |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      " |          the default is `'epoch'`.\n",
      " |      double_precision : The number of decimal places to use when encoding\n",
      " |          floating point values, default 10.\n",
      " |      force_ascii : force encoded string to be ASCII, default True.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object with filtered info axis\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pd.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer')\n",
      " |      Pickle (serialize) object to input file path.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string\n",
      " |          File path\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      " |          a string representing the compression to use in the output file\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table\n",
      " |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      " |      flavor : 'sqlite', default None\n",
      " |          DEPRECATED: this parameter will be removed in a future version,\n",
      " |          as 'sqlite' is the only supported option if SQLAlchemy is not\n",
      " |          installed.\n",
      " |      schema : string, default None\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          - fail: If table exists, do nothing.\n",
      " |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      " |          - append: If table exists, insert data. Create if does not exist.\n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, default None\n",
      " |          If not None, then rows will be written in batches of this size at a\n",
      " |          time.  If None, all rows will be written at once.\n",
      " |      dtype : dict of column name to SQL type, default None\n",
      " |          Optional specifying the datatype for columns. The SQL type should\n",
      " |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncates a sorted NDFrame before and/or after some particular\n",
      " |      index value. If the axis contains only datetime values, before/after\n",
      " |      parameters are converted to datetime values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date\n",
      " |          Truncate before index value\n",
      " |      after : date\n",
      " |          Truncate after index value\n",
      " |      axis : the truncation axis, defaults to the stat axis\n",
      " |      copy : boolean, default is True,\n",
      " |          return a copy of the truncated section\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      truncated : type of caller\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      infer_dst : boolean, default False (DEPRECATED)\n",
      " |          Attempt to infer fall dst-transition hours based on order\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is True and otherwise are from\n",
      " |      other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          If cond is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Fast label-based scalar accessor\n",
      " |      \n",
      " |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |  \n",
      " |  iat\n",
      " |      Fast integer location scalar accessor.\n",
      " |      \n",
      " |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierachical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Purely label-location based indexer for selection by label.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |        to usual python slices, **both** the start and the stop are included!).\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  is_copy = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for a object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TimeSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
